{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples using starlink-pywrapper: Introduction\n",
    "\n",
    "This can be viewed and downloaded as an interactive jupyter notebook from https://github.com/Starlink/starlink-pywrapper/blob/master/doc/examples-notebook-intro.ipynb\n",
    "\n",
    "This presents a guided set of examples running through some of the basics of using the `starlink-pywrapper` package to script Starlink Software Suite commands from Python. It uses the example file `scuba2_map.sdf` provided in http://ftp.eao.hawaii.edu/jcmt/usersmeetings/JCMT_tutorial_2018_Starlink_Analysis.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Starlink-pywrapper provides wrappers around the normal Starlink packages like KAPPA, CUPID etc, to make them easier to call from python, and so you don't have to use shell escapes in your arguments. It requires you to have a functioning Starlink Software Suite install on your computer and to know where Starlink is located, but it does not require you to run the Starlink setup scripts. It also packages up various parts of the help so that they are easily available within your python session.\n",
    "\n",
    "This package provides wrappers for the commands in the Starlink packages KAPPA, CUPID, SMURF, POLPACK, PICARD, ATOOLS and FLUXES. There is also an (untested) wrapper around the Starlink Figaro package.\n",
    "\n",
    "\n",
    "### Links:\n",
    "\n",
    " - http://starlink-pywrapper.readthedocs.io/en/latest/index.html\n",
    " - https://github.com/Starlink/starlink-pywrapper\n",
    " - http://starlink.eao.hawaii.edu\n",
    "\n",
    "\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This package depends on the `starlink-pyhds` package (which  is a low level package that allows you to read and write `.sdf` files within Python), and which itself depends on the `numpy` package. You can install this package and its dependencies with\n",
    "\n",
    "`pip install starlink-pywrapper`\n",
    "\n",
    "This package should work in either Python 2.7 or Python 3.5+."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Setting up the package\n",
    "1. Differences from standard Starlink\n",
    "1. Basic usage\n",
    "1. Getting help with the package\n",
    "1. More advanced features\n",
    "1. Running an ORAC-DR Reduction\n",
    "1. Running many ORAC-DR reductions\n",
    "\n",
    "\n",
    "\n",
    "## Setting up the package.\n",
    "\n",
    "First of all, you need to import the package and let it know where Starlink is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from starlink import wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This warning message just means that I hadn't set the `$STARLINK_DIR` environmental variable, so the wrapper doesn't know where to find your installation of Starlink. If you had set the `$STARLINK_DIR` environmental variable before you started Python, then the wrapper would automatically use that Starlink installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually tell the wrapper where Starlink is with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrapper.change_starpath('/star')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the path ``/star` to the path to your own Starlink installation.\n",
    "You don't have to reimport the package after changing the `starpath`.\n",
    "\n",
    "If you ever can't remember which Starlink you are using, look at the `wrapper.starpath`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/star\n"
     ]
    }
   ],
   "source": [
    "print(wrapper.starpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences from standard Starlink\n",
    "This wrapper provides pythonic calling of Starlink commands, and is designed primarily for scripting. Therefore it has altered or removed some of the features you may be used to if you are experienced at using the command line Starlink.\n",
    "\n",
    "1. Using this wrapper, Starlink will **not** remember your previously used values for any of the commands.\n",
    "1. For keyword arguments, you have to give the full keyword name (shortening to a unique value isn't possible in this wrapper)\n",
    "1. Starlink will not prompt you if you forget a keyword argument that is needed, the command will instead fail with an error.\n",
    "1. Interactive features of some Starlink programs will not work.\n",
    "\n",
    "### Unexpected *features* if you're used to Python\n",
    "\n",
    "The way in which Starlink calls commands is very different from Python. The package attempts to neatly divide all the possible arguments for a command into `required` positional arguments and `optional` keyword arguments. However, often you will **have** to give some of the keyword arguments to run the command successfully. Hopefully the documentation on each command should make this clear. Occasionally there will be a required argument that you don't actually need -- normally you can safely give any value to these without causing any problems.\n",
    "\n",
    "It is possible that the automatic generator script that creates the documentation and call signatures for the commands could have a bug such that the resulting `starlink-pywrapper` command cannot work succesfully. If you run into any issue like this, please let me know so I can fix this (s.graves AT eaobservatory.org).\n",
    "\n",
    "## Basic usage of the commands.\n",
    "\n",
    "The commands should be called like normal python functions. For example, to call the KAPPA `stats` function you would run (replace  `'Starlink_Analysis/scuba2_map.sdf'` with a path to an NDF file on your own machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness    29.107865318223343\n",
      "maxcoord    [-1.3381681735838045, 0.021788981266010584, 0.00085]\n",
      " numgood    39948\n",
      "  minwcs    18:53:46.073, 1:14:14.29, 0.00085\n",
      " minimum    -800.1018996019743\n",
      "   order    False\n",
      "  numbad    18133\n",
      "   sigma    887.2211091888624\n",
      "  numpix    58081\n",
      " maximum    48378.649881284786\n",
      "    mean    95.57703057878183\n",
      "     ndf    Starlink_Analysis/scuba2_map.sdf\n",
      "  maxpos    [0, 0, 1]\n",
      "    comp    DATA\n",
      "  maxwcs    18:53:18.867, 1:14:54.30, 0.00085\n",
      "mincoord    [-1.3361896752346525, 0.02159501271504439, 0.00085]\n",
      "   total    3818111.2175611774\n",
      "  minpos    [-102, -10, 1]\n",
      "kurtosis    1147.2814951588975\n"
     ]
    }
   ],
   "source": [
    "from starlink import kappa\n",
    "file =  'Starlink_Analysis/scuba2_map.sdf'\n",
    "statsvals = kappa.stats(file)\n",
    "print(statsvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands are easily called as `<package>.<commandname>(arguments, keyword1=...)`\n",
    "\n",
    "Required (positional) arguments can be given either by position as above  or you can use the full name and pass the value as if it was a keyword. For example, you can pass the value `file` to the`ndf` argument of `kappa.stats` in either of these two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statsvals = kappa.stats(file)\n",
    "statsvals = kappa.stats(ndf=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it takes more typing, for complex command calls it is often clearer when you look back at a script if you use the second appraoch and give the argument name before each argument.\n",
    "\n",
    "Optional (keyword) arguments are listed in the inline help (see the section `Getting help with the package` below), and are passed like normal Python keyword arguments. For example, the `order` and `comp` options can be changed from their defaults as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness    3.9059048292368095\n",
      "maxcoord    [-1.337915996605891, 0.024154866836891307, 0.00085]\n",
      " numgood    39948\n",
      "  median    21.865963058563082\n",
      "  minwcs    18:53:19.667, 1:16:26.30, 0.00085\n",
      " minimum    10.638659143775554\n",
      "   order    True\n",
      "  numbad    18133\n",
      "   sigma    50.65975753759802\n",
      "  numpix    58081\n",
      " maximum    1157.3041341557991\n",
      "    mean    41.05555477058478\n",
      "     ndf    Starlink_Analysis/scuba2_map.sdf\n",
      "  maxpos    [-13, 122, 1]\n",
      "    comp    ERROR\n",
      "  maxwcs    18:53:22.334, 1:23:02.30, 0.00085\n",
      "mincoord    [-1.33810998137446, 0.022235009763934978, 0.00085]\n",
      "   total    1640087.3019753105\n",
      "  minpos    [-3, 23, 1]\n",
      "kurtosis    26.029946463873603\n"
     ]
    }
   ],
   "source": [
    "statsvals = kappa.stats(file, order=True, comp='ERROR')\n",
    "print(statsvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returned values\n",
    "\n",
    "The return object is a [`namedtuple`](https://docs.python.org/3/library/collections.html#collections.namedtuple) instance. The values in the object are automatically populated from the values written into the `$ADAM_DIR/<commandname>.sdf` parameter file. If you have used the `parget` command in Starlink to programmatically get return values this should be familiar to you -- the names will be the same.\n",
    "\n",
    "You access fields in the output value as attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.865963058563082 <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(statsvals.median, type(statsvals.median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full list of fields programmatically, you can look at the `returnobj._fields` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('skewness', 'maxcoord', 'numgood', 'median', 'minwcs', 'minimum', 'order', 'numbad', 'sigma', 'numpix', 'maximum', 'mean', 'ndf', 'maxpos', 'comp', 'maxwcs', 'mincoord', 'total', 'minpos', 'kurtosis')\n"
     ]
    }
   ],
   "source": [
    "print(statsvals._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This return value lets you use the calculated values of Starlink commands in your scripts.\n",
    "\n",
    "Commands that primarly produce an output file rather than calculate values may not write anything very interesting to the return value; often it will just repeat the values of the parameters you set (and the default paramters you didn't give) from the command line call. For example, if we look at the output of  CONVERT's NDF2FITS command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       in_    Starlink_Analysis/scuba2_map.sdf\n",
      "       out    !scuba2_map.fits\n",
      "    bitpix    0\n",
      "   proexts    False\n",
      "   profits    True\n",
      "    native    False\n",
      "  encoding    Auto\n",
      "    duplex    False\n",
      " container    False\n",
      "  checksum    True\n",
      "      comp    A\n",
      "  allowtab    True\n",
      "provenance    None\n",
      "    prohis    True\n"
     ]
    }
   ],
   "source": [
    "from starlink import convert\n",
    "\n",
    "a = convert.ndf2fits(in_=file, out='!scuba2_map.fits')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the `a.out` value is exactly as you passed the filename to `out` in the function call -- it does not represent the newly written file name itself. Here, the function call had a prepended exclamation mark, which allows you to overwrite a FITS file of the same name. The produced file on disk does not have that exclamation mark, but this is not shown to you in the `a.out` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.isfile(a.out), os.path.isfile('scuba2_map.fits'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see that the parameter name 'in' from Starlink has been translated to `in_` for the Python wrapper; this is because `in` is a Python reserved name, so it has had an underscore attached to its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help with the package\n",
    "\n",
    "This package attempts to bundle some of the most useful help with the package. You can see a short summary of a command and its python call signature and allowed keywords with the normal Python `help` function, or with the jupyter magic command `modulename.commandname?`. These are intended to be of use when you are running interactive sessions, either in the terminal or in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function add in module starlink.kappa:\n",
      "\n",
      "add(in1, in2, out, **kwargs)\n",
      "    Adds two NDF data structures.\n",
      "    \n",
      "    Runs the command: $KAPPA_DIR/add .\n",
      "    \n",
      "    Arguments\n",
      "    ---------\n",
      "    in1 : str,filename\n",
      "        First input NDF\n",
      "    \n",
      "    in2 : str,filename\n",
      "        Second input NDF\n",
      "    \n",
      "    out : str,filename\n",
      "        Output NDF\n",
      "    \n",
      "    \n",
      "    Keyword Arguments\n",
      "    -----------------\n",
      "    title : str\n",
      "        Title for output NDF [!]\n",
      "    \n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See http://www.starlink.ac.uk/cgi-bin/htxserver/sun95.htx/sun95.html?xref_ADD\n",
      "    for full documentation of this command in the latest Starlink release\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from starlink import kappa, cupid\n",
    "help(kappa.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the help it should include a URL taking you to the full Starlink documentation of this command (not specific to using Python to call it.) This will include a lot more detail on the command and its options.\n",
    "\n",
    "You can also see the module help -- this will include the version of starlink these wrappers were generated for, as well as the help (same as above) on all the commands in the module. Warning: this is very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module starlink.cupid in starlink:\n",
      "\n",
      "NAME\n",
      "    starlink.cupid - Runs commands from the Starlink CUPID package.\n",
      "\n",
      "DESCRIPTION\n",
      "    Autogenerated from the starlink .hlp and .ifl files,\n",
      "    by starlink-pywrapper/helperscripts/generate_functions.py.\n",
      "    \n",
      "    Starlink version: 2018A\n",
      "    b6ca36bf8884802759017298539489d11795861e (2018-07-06 09:36:39)\n",
      "\n",
      "FUNCTIONS\n",
      "    clumpinfo(ndf, **kwargs)\n",
      "        Obtain information about one or more previously identified clumps.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/clumpinfo .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        ndf : str,filename\n",
      "            Input NDF containing clump identifications\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        clumps : str\n",
      "            The indices of the clumps to use [ALL]\n",
      "        \n",
      "        quiet : bool\n",
      "            Supress screen output? [FALSE]\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        flbnd : List[float]\n",
      "        \n",
      "        fubnd : List[float]\n",
      "        \n",
      "        lbound : List[int]\n",
      "        \n",
      "        nclumps : int\n",
      "        \n",
      "        ubound : List[int]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_CLUMPINFO\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    cupidhelp(*args, **kwargs)\n",
      "        Display information about CUPID.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/cupidhelp .\n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        topic : str\n",
      "            Help topic [\" \"]\n",
      "        \n",
      "        subtopic : str\n",
      "            Help subtopic [\" \"]\n",
      "        \n",
      "        subsubtopic : str\n",
      "            Help subsubtopic [\" \"]\n",
      "        \n",
      "        subsubsubtopic : str\n",
      "            Help subsubsubtopic [\" \"]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_CUPIDHELP\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    extractclumps(mask, data, out, outcat, **kwargs)\n",
      "        Extract previously identified clumps of emission from an NDF.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/extractclumps .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        mask : str,filename\n",
      "            Input mask NDF\n",
      "        \n",
      "        data : str,filename\n",
      "            Input data NDF\n",
      "        \n",
      "        out : str,filename\n",
      "            Output mask NDF\n",
      "        \n",
      "        outcat : str\n",
      "            Output catalogue\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        backoff : bool\n",
      "            Remove background when finding clump sizes? [TRUE]\n",
      "        \n",
      "        deconv : bool\n",
      "            Correct clump parameters for beam smoothing? [TRUE]\n",
      "        \n",
      "        fwhmbeam : float\n",
      "            Spatial beam width in pixels [dyn.]\n",
      "        \n",
      "        jsacat : str\n",
      "            Output JSA-style catalogue [!]\n",
      "        \n",
      "        logfile : str\n",
      "            Name of output log file [!]\n",
      "        \n",
      "        shape : str\n",
      "            Spatial clump shape in output catalogue [dyn.]\n",
      "        \n",
      "        velores : float\n",
      "            Velocity resolution in channels [dyn.]\n",
      "        \n",
      "        wcspar : bool\n",
      "            Use WCS units in the output catalogue? [dyn.]\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        nclumps : int\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_EXTRACTCLUMPS\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    findback(in_, out, **kwargs)\n",
      "        Estimate the background in an NDF by removing small scale structure.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/findback .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        `in_` : str,filename\n",
      "            Input NDF\n",
      "        \n",
      "        out : str,filename\n",
      "            Output NDF\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        box : List[int]\n",
      "            Filter dimensions, in pixels [9]\n",
      "        \n",
      "        msg_filter : str\n",
      "            Information level [NORM]\n",
      "        \n",
      "        newalg : bool\n",
      "            Use experimental algorithm variations? [FALSE]\n",
      "        \n",
      "        rms : float\n",
      "            RMS noise level\n",
      "        \n",
      "        sub : bool\n",
      "            Subtract background from input data? [FALSE]\n",
      "        \n",
      "        wlim : float\n",
      "            Weight limit for good output pixels [0.3]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_FINDBACK\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    findclumps(in_, out, **kwargs)\n",
      "        Identify clumps of emission within a 1, 2 or 3 dimensional NDF.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/findclumps .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        `in_` : str,filename\n",
      "            Input NDF\n",
      "        \n",
      "        out : str,filename\n",
      "            Output NDF\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        outcat : str\n",
      "            Output KAPPA-style catalogue [!]\n",
      "        \n",
      "        method : str\n",
      "            Clump identification algorithm [current value]\n",
      "        \n",
      "        backoff : bool\n",
      "            Remove background when finding clump sizes? [dyn.]\n",
      "        \n",
      "        config : str\n",
      "            Algorithm tuning parameters [current value]\n",
      "        \n",
      "        deconv : bool\n",
      "            Correct clump parameters for beam smoothing? [TRUE]\n",
      "        \n",
      "        jsacat : str\n",
      "            Output JSA-style catalogue [!]\n",
      "        \n",
      "        logfile : str\n",
      "            Name of output log file [!]\n",
      "        \n",
      "        msg_filter : str\n",
      "            Information level [NORM]\n",
      "        \n",
      "        perspectrum : bool\n",
      "            Process spectra independently of neighbouring spectra? [FALSE]\n",
      "        \n",
      "        qout : str,filename\n",
      "            Copy of input NDF with Quality mask [!]\n",
      "        \n",
      "        repconf : bool\n",
      "            Report supplied configuration? [current value]\n",
      "        \n",
      "        rms : float\n",
      "            RMS noise level\n",
      "        \n",
      "        shape : str\n",
      "            Spatial clump shape in output catalogue [dyn.]\n",
      "        \n",
      "        wcspar : bool\n",
      "            Use WCS units in the output catalogue? [dyn.]\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        nclumps : int\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_FINDCLUMPS\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    makeclumps(out, outcat, **kwargs)\n",
      "        Create simulated data containing clumps and noise.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/makeclumps .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        out : str,filename\n",
      "            Output NDF\n",
      "        \n",
      "        outcat : str\n",
      "            Output catalogue\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        angle : List[float]\n",
      "            Mean and width of spatial position angles in degs [current value]\n",
      "        \n",
      "        beamfwhm : float\n",
      "            Spatial FWHM of instrument beam in pixels [current value]\n",
      "        \n",
      "        deconv : bool\n",
      "            Correct clump parameters for beam smoothing? [TRUE]\n",
      "        \n",
      "        fwhm1 : List[float]\n",
      "            Mean and width of FWHMs on pixel axis 1 in pixels [current value]\n",
      "        \n",
      "        fwhm2 : List[float]\n",
      "            Mean and width of FWHMs on pixel axis 2 in pixels [current value]\n",
      "        \n",
      "        fwhm3 : List[float]\n",
      "            Mean and width of FWHMs on pixel axis 3 in pixels [current value]\n",
      "        \n",
      "        grid : int\n",
      "            Margin to place round outside of regular grid [!]\n",
      "        \n",
      "        lbnd : List[int]\n",
      "            Lower pixel bounds of output array [1,1]\n",
      "        \n",
      "        like : str,filename\n",
      "            An NDF to define the output WCS [!]\n",
      "        \n",
      "        model : str,filename\n",
      "            Output NDF without noise\n",
      "        \n",
      "        nclump : List[int]\n",
      "            Number of clumps to create [50]\n",
      "        \n",
      "        pardist : str\n",
      "            Parameter distribution [current value]\n",
      "        \n",
      "        peak : List[float]\n",
      "            Mean and width of clump peak values [current value]\n",
      "        \n",
      "        precat : bool\n",
      "            Create catalogue before instrumental smoothing is applied? [FALSE]\n",
      "        \n",
      "        rms : float\n",
      "            RMS noise to add to data [current value]\n",
      "        \n",
      "        shape : str\n",
      "            Spatial clump shape in output catalogue [\"None\"]\n",
      "        \n",
      "        trunc : float\n",
      "            Truncation level for clumps [current value]\n",
      "        \n",
      "        ubnd : List[int]\n",
      "            Upper pixel bounds of output array [200,200]\n",
      "        \n",
      "        velfwhm : float\n",
      "            FWHM of velocity resolution in pixels [current value]\n",
      "        \n",
      "        vgrad1 : List[float]\n",
      "            Mean and width of vel. gradient on axis 1 [current value]\n",
      "        \n",
      "        vgrad2 : List[float]\n",
      "            Mean and width of vel. gradient on axis 2 [current value]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_MAKECLUMPS\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    outlineclump(*args, **kwargs)\n",
      "        Draw an outline around a 2-dimensional clump identified by CUPID.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/outlineclump.csh .\n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        index : \n",
      "               The integer index or indices of the clumps to be identified.\n",
      "           For multiple indices supply a comma-separated list, using\n",
      "           hyphens to express ranges.  For example \"2,4-6,9\" would draw\n",
      "           the outlines of clumps with indices 2, 4, 5, 6, and 9.\n",
      "        \n",
      "        ndf : \n",
      "               The name of the NDF containing the clump information. This NDF\n",
      "           should have been created using the CUPID:FINDCLUMPS or\n",
      "           CUPID:EXTRACTCLUMPS command. The clump cut-out images contained in\n",
      "           the CUPID extension of this NDF will be used to define the outline\n",
      "           of the clump.\n",
      "        \n",
      "        style : \n",
      "               A group of attribute settings describing the plotting style to\n",
      "           use for the outline.\n",
      "        \n",
      "           A comma-separated list of strings should be given in which each\n",
      "           string is either an attribute setting, or the name of a text\n",
      "           file preceded by an up-arrow character \"^\".  Such text files\n",
      "           should contain further comma-separated lists which will be read\n",
      "           and interpreted in the same manner.  Attribute settings are\n",
      "           applied in the order in which they occur within the list, with\n",
      "           later settings overriding any earlier settings given for the\n",
      "           same attribute.\n",
      "        \n",
      "           Each individual attribute setting should be of the form:\n",
      "        \n",
      "              <name>=<value>\n",
      "        \n",
      "           where <name> is the name of a plotting attribute, and <value>\n",
      "           is the value to assign to the attribute. Default values will be\n",
      "           used for any unspecified attributes.  All attributes will be\n",
      "           defaulted if a null value (!) is supplied.  See section\n",
      "           \"Plotting Attributes\" in SUN/95 for a description of the\n",
      "           available attributes.  Any unrecognised attributes are ignored\n",
      "           (no error is reported).\n",
      "        \n",
      "           The appearance of the clump outline is controlled by the attributes\n",
      "           Colour(Curves), Width(Curves), etc (the synonym Contours may be\n",
      "           used in place of Curves). The contour appearance established in\n",
      "           this way may be modified using parameters PENS, PENROT and\n",
      "           DASHED. [current value]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_OUTLINECLUMP\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "\n",
      "FILE\n",
      "    /home/sgraves/PYTHON/starlink-pywrapper/starlink/cupid.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cupid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make it easier to see what is available in a module, the package contains a `starhelp` command in the `utilities` subpackage. If you call this on a module this will show you a listing of all the commands available in that module, along with a short one line description of what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clumpinfo     :     Obtain information about one or more previously identified clumps.\n",
      "cupidhelp     :     Display information about CUPID.\n",
      "extractclumps :     Extract previously identified clumps of emission from an NDF.\n",
      "findback      :     Estimate the background in an NDF by removing small scale structure.\n",
      "findclumps    :     Identify clumps of emission within a 1, 2 or 3 dimensional NDF.\n",
      "makeclumps    :     Create simulated data containing clumps and noise.\n",
      "outlineclump  :     Draw an outline around a 2-dimensional clump identified by CUPID."
     ]
    }
   ],
   "source": [
    "from starlink.utilities import starhelp\n",
    "starhelp(cupid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call `starhelp` on a command, it will show you the **full** documentation of this Starlink command (not specific to this python wrapper) in .rst format. It will probably be better to look at the normal online Starlink documentation instead (linked at the end of the output seen running a normal `help` or `?` on a command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ADD\n",
      "===\n",
      "\n",
      "\n",
      "Purpose\n",
      "~~~~~~~\n",
      "Adds two NDF data structures\n",
      "\n",
      "\n",
      "Description\n",
      "~~~~~~~~~~~\n",
      "The routine adds two NDF data structures pixel-by-pixel to produce a\n",
      "new NDF.\n",
      "\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "\n",
      "::\n",
      "\n",
      "    \n",
      "       add in1 in2 out\n",
      "       \n",
      "\n",
      "\n",
      "\n",
      "ADAM parameters\n",
      "~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "IN1 = NDF (Read)\n",
      "````````````````\n",
      "First NDF to be added.\n",
      "\n",
      "\n",
      "\n",
      "IN2 = NDF (Read)\n",
      "````````````````\n",
      "Second NDF to be added.\n",
      "\n",
      "\n",
      "\n",
      "OUT = NDF (Write)\n",
      "`````````````````\n",
      "Output NDF to contain the sum of the two input NDFs.\n",
      "\n",
      "\n",
      "\n",
      "TITLE = LITERAL (Read)\n",
      "``````````````````````\n",
      "Value for the title of the output NDF. A null value will cause the\n",
      "title of the NDF supplied for parameter IN1 to be used instead. [!]\n",
      "\n",
      "\n",
      "\n",
      "Examples\n",
      "~~~~~~~~\n",
      "add a b c\n",
      "This adds the NDF called b to the NDF called a, to make the NDF called\n",
      "c. NDF c inherits its title from a.\n",
      "add out=c in1=a in2=b title=\"Co-added image\"\n",
      "This adds the NDF called b to the NDF called a, to make the NDF called\n",
      "c. NDF c has the title \"Co-added image\".\n",
      "\n",
      "\n",
      "\n",
      "Notes\n",
      "~~~~~\n",
      "\n",
      "\n",
      "+ The output NDF contains the simple sum of the input NDFs.\n",
      "Inparticularly, the input variances are not used as weights. For a\n",
      "weighted co-addition, use CCDPACK:MAKEMOS.\n",
      "+ If the two input NDFs have different pixel-index bounds, then they\n",
      "  will be trimmed to match before being added. An error will result if\n",
      "  they have no pixels in common.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Related Applications\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "KAPPA: CADD, CDIV, CMULT, CSUB, DIV, MATHS, MULT, SUB.\n",
      "\n",
      "\n",
      "Copyright\n",
      "~~~~~~~~~\n",
      "Copyright (C) 1990, 1992 Science & Engineering Research Council.\n",
      "Copyright (C) 1995, 1998, 2004 Central Laboratory of the Research\n",
      "Councils. Copyright (C) 2007, 2012 Science & Technology Facilities\n",
      "Council. All Rights Reserved.\n",
      "\n",
      "\n",
      "Licence\n",
      "~~~~~~~\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either Version 2 of the License, or (at\n",
      "your option) any later version.\n",
      "This program is distributed in the hope that it will be useful, but\n",
      "WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n",
      "General Public License for more details.\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program; if not, write to the Free Software\n",
      "Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n",
      "02110-1301, USA.\n",
      "\n",
      "\n",
      "Implementation Status\n",
      "~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "+ This routine correctly processes the WCS, AXIS, DATA, QUALITY,\n",
      "LABEL, TITLE, HISTORY, and VARIANCE components of an NDF data\n",
      "structure and propagates all extensions.\n",
      "+ The UNITS component is propagated only if it has the same value in\n",
      "both input NDFs.\n",
      "+ Processing of bad pixels and automatic quality masking are\n",
      "supported.\n",
      "+ All non-complex numeric data types can be handled.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "starhelp(kappa.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the terminal output\n",
    "\n",
    "If you've previously only examined the output of Starlink commands by reading or grepping the output written to the terminal, hopefully the return values shown here will be useful. Generally, you should not need to grep the string output of a Starlink command.\n",
    "\n",
    "\n",
    "However, particularly while you are developing your script you may still sometimes want to see with the *normal* output, so this module does provide a means of doing that. The simplest way is to turn the standard python logging module into DEBUG mode. When you do that, the module will write both the full Starlink command it is running (useful if you run into problems) as well as the normal terminal output you would see if you ran this on the command line. For example, if you turn on DEBUG logging and run the `kappa.stats` command you will see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:starlink.wrapper:['/star/bin/kappa/stats', 'Starlink_Analysis/scuba2_map.sdf', 'order=True', 'comp=ERROR']\n",
      "DEBUG:starlink.wrapper:\n",
      "   Pixel statistics for the NDF structure /home/sgraves/PYTHON/starlink-pywrapper/doc/Starlink_Analysis/scuba2_map\n",
      "\n",
      "      Title                     : G34.3\n",
      "      NDF array analysed        : ERROR\n",
      "\n",
      "         Pixel sum              : 1640087.30197531\n",
      "         Pixel mean             : 41.0555547705848\n",
      "         Standard deviation     : 50.659757537598\n",
      "         Skewness               : 3.90590482923681\n",
      "         Kurtosis               : 26.0299464638736\n",
      "         Minimum pixel value    : 10.6386591437756\n",
      "            At pixel            : (-3, 23, 1)\n",
      "            Co-ordinate         : (18:53:19.667, 1:16:26.30, 0.00085)\n",
      "         Maximum pixel value    : 1157.3041341558\n",
      "            At pixel            : (-13, 122, 1)\n",
      "            Co-ordinate         : (18:53:22.334, 1:23:02.30, 0.00085)\n",
      "         Pixel median           : 21.8659630585631\n",
      "         Total number of pixels : 58081\n",
      "         Number of pixels used  : 39948 (68.8%)\n",
      "         No. of pixels excluded : 18133 (31.2%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.root.setLevel(logging.DEBUG)\n",
    "\n",
    "statsvals = kappa.stats(ndf=file, order=True, comp='ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn this back to only showing INFO level logging information, you would run (in a jupyter notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a normal Python script or interactive session (not a jupyter notebook) you would normally run\n",
    "```python\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel('DEBUG')\n",
    "```\n",
    "\n",
    "#### Accessing the Standard Output as a string\n",
    "Sometimes you may want to get the output that is normally written to the terminal as a string. You shouldn't normally need this, but if you do then pass the keyword argument `returnstdout=True` to any of the Starlink commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Pixel statistics for the NDF structure /home/sgraves/PYTHON/starlink-pywrapper/doc/Starlink_Analysis/scuba2_map\n",
      "\n",
      "      Title                     : G34.3\n",
      "      NDF array analysed        : ERROR\n",
      "\n",
      "         Pixel sum              : 1640087.30197531\n",
      "         Pixel mean             : 41.0555547705848\n",
      "         Standard deviation     : 50.659757537598\n",
      "         Skewness               : 3.90590482923681\n",
      "         Kurtosis               : 26.0299464638736\n",
      "         Minimum pixel value    : 10.6386591437756\n",
      "            At pixel            : (-3, 23, 1)\n",
      "            Co-ordinate         : (18:53:19.667, 1:16:26.30, 0.00085)\n",
      "         Maximum pixel value    : 1157.3041341558\n",
      "            At pixel            : (-13, 122, 1)\n",
      "            Co-ordinate         : (18:53:22.334, 1:23:02.30, 0.00085)\n",
      "         Pixel median           : 21.8659630585631\n",
      "         Total number of pixels : 58081\n",
      "         Number of pixels used  : 39948 (68.8%)\n",
      "         No. of pixels excluded : 18133 (31.2%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statsvals, stdout = kappa.stats(ndf=file, order=True, comp='ERROR', returnstdout=True)\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This causes the command to return a tuple of the normal returned object and the Starlink terminal output as a string.\n",
    "\n",
    "\n",
    "### Shell Escapes\n",
    "Shell escapes are the sets of quotes or backslashes that you have to use when running Starlink in a shell if you have any special characters in your command line call -- they `escape` you from the shell's attempt to interpret those charaters.\n",
    "\n",
    "Unlike when you call Starlink commands directly in your terminal, this python wrapper doesn't go through a shell, so you do not have to use shell escapes around string values. For example, when providing an NDF section to only include a 6 by 6 pixel square of your map you would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewness    0.8710338530851028\n",
      "maxcoord    [-1.3381875707353537, 0.02178898127010817, 0.00085]\n",
      " numgood    36\n",
      "  minwcs    18:53:17.533, 1:15:14.30, 0.00085\n",
      " minimum    15.635780592588478\n",
      "   order    False\n",
      "  numbad    0\n",
      "   sigma    43.44768072049565\n",
      "  numpix    36\n",
      " maximum    145.2239807802179\n",
      "    mean    56.78561067384343\n",
      "     ndf    Starlink_Analysis/scuba2_map.sdf(0:5,0:5)\n",
      "  maxpos    [1, 0]\n",
      "    comp    ERROR\n",
      "  maxwcs    18:53:18.600, 1:14:54.30, 0.00085\n",
      "mincoord    [-1.338265159505499, 0.02188594394031615, 0.00085]\n",
      "   total    2044.2819842583647\n",
      "  minpos    [5, 5]\n",
      "kurtosis    -0.8029823301673149\n",
      "Starlink_Analysis/scuba2_map.sdf(0:5,0:5)\n"
     ]
    }
   ],
   "source": [
    "# No need to use shell escapes! E.g., if you want to pass an ndfsection you can do\n",
    "section = '(0:5,0:5)'\n",
    "statsvals = kappa.stats(ndf=file+section, comp='ERROR')\n",
    "print(statsvals)\n",
    "print(statsvals.ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as opposed to running in your terminal, where you have to do:\n",
    "```bash\n",
    "stats \"'../Starlink_Analysis/scuba2_map.sdf(0:5,0:5)'\"\n",
    "# or\n",
    "stats ../Starlink_Analysis/scuba2_map.sdf\\(0:5,0:5\\)\n",
    "```\n",
    "\n",
    "Unfortunately you still can't include spaces in your NDF section (you also can't on the command line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Starlink error occured during command:\n/star/bin/kappa/stats ('Starlink_Analysis/scuba2_map.sdf(0:5, 0:5)',)\n stdout and stderr are appended below.\n!! GRP1_PAREL: Un-matched delimiters '()' found in\n!     'Starlink_Analysis/scuba2_map.sdf(0:5,'.\n!  GRP_GRPEX: Unable to read names from group expression\n!     Starlink_Analysis/scuba2_map.sdf(0:5,\n!  Error obtaining a group of existing NDFs using group expression\n!     \"Starlink_Analysis/scuba2_map.sdf(0:5,\"\n!  Unable to associate a group of NDFs with parameter NDF.\n!  STATS: Error computing simple statistics for an NDF's pixels.\n!  Application exit status GRP__INVEL, Invalid element syntax given\n!  Starlink_Analysis/scuba2_map.sdf(0:5, 0:5) comp=ERROR\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-69c6731b4b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(0:5, 0:5)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstatsvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PYTHON/starlink-pywrapper/starlink/kappa.py\u001b[0m in \u001b[0;36mstats\u001b[0;34m(ndf, **kwargs)\u001b[0m\n\u001b[1;32m   9070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9071\u001b[0m     \"\"\"\n\u001b[0;32m-> 9072\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarcomm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$KAPPA_DIR/stats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PYTHON/starlink-pywrapper/starlink/wrapper.py\u001b[0m in \u001b[0;36mstarcomm\u001b[0;34m(command, commandname, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} does not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madamfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Starlink error occured during command:\n/star/bin/kappa/stats ('Starlink_Analysis/scuba2_map.sdf(0:5, 0:5)',)\n stdout and stderr are appended below.\n!! GRP1_PAREL: Un-matched delimiters '()' found in\n!     'Starlink_Analysis/scuba2_map.sdf(0:5,'.\n!  GRP_GRPEX: Unable to read names from group expression\n!     Starlink_Analysis/scuba2_map.sdf(0:5,\n!  Error obtaining a group of existing NDFs using group expression\n!     \"Starlink_Analysis/scuba2_map.sdf(0:5,\"\n!  Unable to associate a group of NDFs with parameter NDF.\n!  STATS: Error computing simple statistics for an NDF's pixels.\n!  Application exit status GRP__INVEL, Invalid element syntax given\n!  Starlink_Analysis/scuba2_map.sdf(0:5, 0:5) comp=ERROR\n\n"
     ]
    }
   ],
   "source": [
    "section = '(0:5, 0:5)'\n",
    "statsvals = kappa.stats(ndf=file+section, comp='ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling\n",
    "The above example illustrates error handling. As well as the normal Python traceback seen at the top of the screen, you should also be shown the Starlink command that was run, its arguments, and the actual Starlink-generated error message. In this case, if you read the message you can see that it is trying to evaluate `'Starlink_Analysis/scuba2_map.sdf(0:5,'` as an NDF section, and of course failing. This is because the space we included in the NDF section causes Starlink to break the parameter at that point.\n",
    "\n",
    "You can use normal Python exception handling to deal with these Starlink errors, in a normal ```try ... except ...``` block.\n",
    "\n",
    "Currently ORAC-DR calls through `wrapper.oracdr` (see below) don't raise an error when they have problems; instead they produce a return value. This will probably be changed in the next version of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the FITS header\n",
    "\n",
    "There is a utility function in the `starlink.utilities` module which will read in the FITS headers of an NDF file and convert it into an Astropy `fitsheader` object. This requires the `astropy` package to be installed and available to Python. It is used as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TELESCOP= 'JCMT    '           / Name of Telescope                              \n",
       "ORIGIN  = 'Joint Astronomy Centre, Hilo' / Origin of file                       \n",
       "                                                                                \n",
       "        ---- x,y,z triplet for JCMT relative to centre of earth ----            \n",
       "ALT-OBS =               4120.0 / [m] Height of observatory above sea level      \n",
       "LAT-OBS =      19.822838905884 / [deg] Latitude of Observatory                  \n",
       "LONG-OBS=    -155.477027838737 / [deg] East longitude of observatory            \n",
       "OBSGEO-X=    -5464587.04742954 / [m]                                            \n",
       "OBSGEO-Y=    -2492998.88150847 / [m]                                            \n",
       "OBSGEO-Z=     2150659.39661545 / [m]                                            \n",
       "ETAL    =                 0.85 / Telescope efficiency                           \n",
       "                                                                                \n",
       "        ---- OMP and ORAC-DR Specific ----                                      \n",
       "PROJECT = 'M12AEC05'           / PATT number                                    \n",
       "RECIPE  = 'REDUCE_SCAN'        / ORAC-DR recipe                                 \n",
       "DRGROUP =                      / Data Reduction group ID                        \n",
       "MSBID   = '4c98abe9be364a498025a4e3a92a244d' / Id of minimum scheduable block   \n",
       "MSBTID  = 'JCMT_1335889978_866944' / Transaction ID of MSB                      \n",
       "SURVEY  =                      / Survey Name                                    \n",
       "RMTAGENT=                      / Name of Remote Agent                           \n",
       "AGENTID =                      / Unique identifier for remote agent             \n",
       "                                                                                \n",
       "        ---- Obs Id, Date, Pointing Info ----                                   \n",
       "OBJECT  = 'G34.3   '           / Object of interest                             \n",
       "STANDARD=                    F / True if the observation is a calibrator        \n",
       "OBSNUM  =                   68 / Observation number                             \n",
       "OBSEND  =                    F / True if file is last subscan in obs.           \n",
       "UTDATE  =             20120501 / UT Date as integer in yyyymmdd format          \n",
       "DATE-OBS= '2012-05-01T16:45:43' / UTC Datetime of start of observation          \n",
       "DATE-END= '2012-05-01T16:51:01' / UTC Datetime of end of observation            \n",
       "DUT1    =  -6.28793351692571E-6 / [d] UT1-UTC correction                        \n",
       "OBSID   = 'scuba2_00068_20120501T164451' / Unique observation identifier        \n",
       "OBSIDSS = 'scuba2_68_20120501T164451_850' / Unique observation subsys identifier\n",
       "INSTAP  =                      / Subarray at tracking centre (if any)           \n",
       "INSTAP_X=                  0.0 / [arcsec] Aperture X off. rel. to instr centre  \n",
       "INSTAP_Y=                  0.0 / [arcsec] Aperture Y off. rel. to instr centre  \n",
       "AMSTART =     1.24858665086979 / Airmass at start of sub-scan                   \n",
       "AMEND   =     1.26820260751962 / Airmass at end of sub-scan                     \n",
       "AZSTART =     243.707071180545 / [deg] Azimuth at sub-scan start                \n",
       "AZEND   =     244.907389754619 / [deg] Azimuth at sub-scan end                  \n",
       "ELSTART =     53.2166648849455 / [deg] Elevation at sub-scan start              \n",
       "ELEND   =     52.0471883170533 / [deg] Elevation at sub-scan end                \n",
       "TRACKSYS= 'J2000   '           / TCS Tracking coordinate system                 \n",
       "BASEC1  =             283.3275 / [deg] Base C1 at sub-scan start                \n",
       "BASEC2  =     1.24951666666667 / [deg] Base C2 at sub-scan start                \n",
       "HSTSTART= '2012-05-01T06:45:43' / HST at start of observation                   \n",
       "HSTEND  = '2012-05-01T06:51:01' / HST at end of observation                     \n",
       "LSTSTART= '01:57:58.1862'      / LST at start of observation                    \n",
       "LSTEND  = '02:03:17.3809'      / LST at end of observation                      \n",
       "                                                                                \n",
       "        ---- Integration time related -----                                     \n",
       "SEQSTART=               139567 / RTS index number of first frame                \n",
       "SEQEND  =               191290 / RTS index number of last frame                 \n",
       "                                                                                \n",
       "        ---- SCUBA-2 Specific ----                                              \n",
       "INSTRUME= 'SCUBA-2 '           / Instrument name                                \n",
       "SHUTTER =                  1.0 / shutter position 0-Closed 1-Open               \n",
       "FILTER  = '850     '           / Filter name                                    \n",
       "WAVELEN =              0.00085 / [m] Filter central wavelength                  \n",
       "BANDWID =               7.0E-5 / [m] Filter bandwidth                           \n",
       "DATAMODE=                    2 / Data Acquisition mode                          \n",
       "BOLODIST=                 6.28 / [arcsec]  Nominal Bolometer spacing            \n",
       "BBHEAT  =                  0.0 / [deg C] Blackbody temperature                  \n",
       "BASETEMP=             0.077007 / [K] Base temperature                           \n",
       "MIXSETP =               8000.0 / [ohms] Mixing chamber set point                \n",
       "SEQCOUNT=                    3 / Setup Sequence Counter                         \n",
       "                                                                                \n",
       "        ---- Environmental Data ----                                            \n",
       "ATSTART =                 -1.4 / [degC] Air temp at start                       \n",
       "ATEND   =                 -1.3 / [degC] Air temp at end                         \n",
       "HUMSTART=                 29.8 / Rel. Humidity at start                         \n",
       "HUMEND  =                 28.5 / Rel. Humidity at end                           \n",
       "BPSTART =                623.5 / [mbar] Pressure at start                       \n",
       "BPEND   =     623.700012207031 / [mbar] Pressure at end                         \n",
       "WNDSPDST=             20.06776 / [km/h] Wind Speed at start                     \n",
       "WNDSPDEN=             22.44806 / [km/h] Wind Speed at end                       \n",
       "WNDDIRST=              53.1384 / [deg] Wind direction, azimuth at start         \n",
       "WNDDIREN=            147.54384 / [deg] Wind direction, azimuth at end           \n",
       "TAU225ST=                0.038 / Tau at 225 GHz from CSO at start               \n",
       "TAU225EN=                0.016 / Tau at 225 GHz from CSO at end                 \n",
       "TAUDATST= '2012-05-01T16:37:00' / Time of TAU225ST observation                  \n",
       "TAUDATEN= '2012-05-01T16:47:00' / Time of TAU225EN observation                  \n",
       "TAUSRC  = 'CSO225GHZ'          / Source of the TAU225 value                     \n",
       "WVMTAUST=   0.0432917852401733 / 186GHz Tau from JCMT WVM at start              \n",
       "WVMTAUEN=   0.0498420448303223 / 186GHz Tau from JCMT WVM at end                \n",
       "WVMDATST= '2012-05-01T16:46:17' / Time of WVMTAUST                              \n",
       "WVMDATEN= '2012-05-01T16:51:35' / Time of WVMTAUEN                              \n",
       "SEEINGST=                      / [arcsec] SAO atmospheric seeing (start)        \n",
       "SEEINGEN=                      / [arcsec] SAO atmospheric seeing (end)          \n",
       "SEEDATST=                      / Date/Time of SEEINGST                          \n",
       "SEEDATEN=                      / Date/Time of SEEINGEN                          \n",
       "FRLEGTST=           2.10770775 / [degC] Mean Front leg temperature - Start      \n",
       "FRLEGTEN=           2.10770775 / [degC] Mean Front Leg temperature -End         \n",
       "BKLEGTST=     1.75453866666667 / [degC] Mean back leg temperature -Start        \n",
       "BKLEGTEN=     1.78628333333333 / [degC] Mean back leg temperature -End          \n",
       "                                                                                \n",
       "        ---- Switching and Map setup for the observation ----                   \n",
       "SAM_MODE= 'scan    '           / Sampling Mode                                  \n",
       "SW_MODE = 'self    '           / Switch Mode: CHOP, PSSW, NONE, etc             \n",
       "INBEAM  =                      / Hardware in the beam                           \n",
       "SEQ_TYPE= 'science '           / Type of sequence                               \n",
       "OBS_TYPE= 'science '           / Type of observation                            \n",
       "CHOP_CRD=                      / Chopping co-ordinate system                    \n",
       "CHOP_FRQ=                      / [Hz] Chop frequency                            \n",
       "CHOP_PA =                      / [deg] Chop PA; 0=in lat, 90=in long            \n",
       "CHOP_THR=                      / [arcsec] Chop throw                            \n",
       "JIGL_CNT=                      / Number of offsets in jiggle pattern            \n",
       "JIGL_NAM=                      / File containing the jiggle offsets             \n",
       "JIG_PA  =                      / [deg] Jiggling PA; 0=in lat, 90=in long        \n",
       "JIG_CRD =                      / Jiggling co-ordinate system                    \n",
       "JIG_SCAL=                      / [arcsec] Scale of jiggle pattern               \n",
       "DRMWGHTS=                      / Name of file containing DREAM weights          \n",
       "MAP_HGHT=                240.0 / [arcsec] Requested height of map               \n",
       "MAP_PA  =                  0.0 / [deg] Requested PA of map                      \n",
       "MAP_WDTH=                240.0 / [arcsec] Requested width of map                \n",
       "LOCL_CRD= 'TRACKING'           / Local offset/map PA co-ordinate system         \n",
       "MAP_X   =                  0.0 / [arcsec] Requested map offset from tel centre  \n",
       "MAP_Y   =                  0.0 / [arcsec] Requested map offset from tel centre  \n",
       "SCAN_CRD= 'AZEL    '           / Co-ordinate system for scanning direction      \n",
       "SCAN_VEL=                155.0 / [arcsec/sec] Scan velocity along scan axis     \n",
       "SCAN_DY =                  0.6 / [arcsec] Scan spacing perp. to scan axis       \n",
       "SCAN_PA =                  0.0 / [deg] Scan PA relative to SAM_CRDS             \n",
       "SCAN_PAT= 'CV_DAISY'           / Scan pattern name                              \n",
       "                                                                                \n",
       "        ---- SMU ----                                                           \n",
       "ALIGN_DX=                 0.03 / SMU tables X axis focus offset                 \n",
       "ALIGN_DY=                 0.23 / SMU tables Y axis focus offset                 \n",
       "FOCUS_DZ=                -0.14 / SMU tables Z axis focus offset                 \n",
       "DAZ     =                -6.44 / SMU azimuth pointing offset                    \n",
       "DEL     =     80.6004943847656 / SMU elevation pointing offset                  \n",
       "UAZ     =     3.35132110490203 / User azimuth pointing offset                   \n",
       "UEL     =     1.71605075792523 / User elevation pointing offset                 \n",
       "                                                                                \n",
       "        ---- JOS parameters ----                                                \n",
       "NUM_CYC =                    1 / Number of times to repeat entire recipe        \n",
       "JOS_MULT=                    1 / MULT from JOS used in total steps calculation  \n",
       "JOS_MIN =                51724 / MIN from JOS used in total steps calculation   \n",
       "NDRKSTEP=                 1724 / Number of RTS steps for each Dark (if any)     \n",
       "STBETDRK=                51724 / Target number of RTS steps between darks       \n",
       "STARTIDX=                    1 / Index into pattern at start of obs             \n",
       "FOCAXIS =                      / Focus Axis to move (X, Y, Z)                   \n",
       "NFOCSTEP=                      / Number of focal position steps (odd number)    \n",
       "FOCSTEP =                      / Distance between focus steps                   \n",
       "FOCPOSN =                      / [mm] Relative SMU position                     \n",
       "                                                                                \n",
       "        ---- Miscellaneous ----                                                 \n",
       "OCSCFG  = 'scuba2_20120501_164423_624439.xml' / OCS config filename             \n",
       "DHSVER  = 'MOD     '           / Data Handling System Version                   \n",
       "SIM_SMU =                    F / True if SMU data is simulated                  \n",
       "SIM_TCS =                    F / True if TCS data is simulated                  \n",
       "SIM_RTS =                    F / True if RTS data is simulated                  \n",
       "SIM_POL =                    T / True if polarization data is simulated         \n",
       "SIMULATE=                    F / True if any data are simulated                 \n",
       "STATUS  = 'NORMAL  '           / Status of end of obervation                    \n",
       "                                                                                \n",
       "        ---- Polarimeter Specific ----                                          \n",
       "POL_MODE= 'UNKNOWN '           / Step-and-integrate (STOP_START) or Spin (CONSTA\n",
       "ROTAFREQ=                  0.0 / [Hz] Spin frequency (if spinning) of polarimete\n",
       "POL_CRD = 'FPLANE  '           / Coordinate system of polarimeter               \n",
       "POL_FAXS=                      / Frequency dependency of waveplate offset of pol\n",
       "POLCALIN=                    F / True if polarimeter calibrator is in the beam  \n",
       "POLWAVIN=                    F / True if polarimeter waveplate is in the beam   \n",
       "POLANLIN=                    F / True if polarimeter analyzer is in the beam    \n",
       "                                                                                \n",
       "        ---- FTS Specific ----                                                  \n",
       "FTS_MODE= 'UNKNOWN '           / Step-and-integrate (STEPINT) or fast-scanning  \n",
       "SCANVEL =                  0.0 / [mm/s] Mirror scan rate in FSCAN mode          \n",
       "FTS_IN  =                    F / True if FTS pickoff mirror is in the beam      \n",
       "SCANDIR =                    0 / 1 -> back to front, -1 -> front to back        \n",
       "STEPDIST=                  0.0 / [mm] Amount to move each step in STEPINT mode  \n",
       "SIM_FTS =                    F / True if FTS data is simulated                  \n",
       "        ---- Metadata Fixups ----                                               \n",
       "BACKEND = 'SCUBA-2 '           / Name of the backend                            \n",
       "                                                                                \n",
       "        ---- Data Processing ----                                               \n",
       "STEPTIME=  0.00615443532520461 / RTS step time during an RTS sequence           \n",
       "EXP_TIME=     23.2952175140381 / [s] Median MAKEMAP exposure time               \n",
       "NUMTILES=                    1 / No. of tiles covering the field                \n",
       "TILENUM =                    1 / Index of this tile (1->NUMTILES)               \n",
       "NCONTIG =                    1 / No. of contig. chunks within supplied data     \n",
       "MEMLOW  =                    F / Was data chunked due to insufficient memory?   \n",
       "NBOLOEFF=     3247.52010376135 / Effective bolometer count                      \n",
       "PIPEVERS= '8ddff2d39647131d2f2c2ab7dcc3a91664e3123c' / Pipeline version         \n",
       "ENGVERS = 'bfdc8534a17c406c59302030ed1c1ae1a1223bd1' / Algorithm engine version \n",
       "PROCVERS= '20170728215828'     / Date of most recent commit                     \n",
       "PRODUCT = 'reduced '           / Pipeline product                               \n",
       "PRODID  = 'reduced-850um'      / Product ID                                     \n",
       "OBSDEC  =     1.24952128998345 / [deg] Reference ICRS Dec coordinate            \n",
       "OBSRABL =     283.467517902583 / [deg] Bottom left ICRS RA coordinate           \n",
       "OBSDECBL=     1.13062919866416 / [deg] Bottom left ICRS Dec coordinate          \n",
       "OBSRATL =     283.467532113428 / [deg] Top left ICRS RA coordinate              \n",
       "OBSDECTL=     1.39729457057628 / [deg] Top left ICRS Dec coordinate             \n",
       "OBSRABR =     283.200800366733 / [deg] Bottom right ICRS RA coordinate          \n",
       "OBSDECBR=     1.13062980612683 / [deg] Bottom right ICRS Dec coordinate         \n",
       "OBSRATR =     283.200787499963 / [deg] Top right ICRS RA coordinate             \n",
       "OBSDECTR=     1.39729532251639 / [deg] Top right ICRS Dec coordinate            \n",
       "FRQSIGLO=     338.721411364953 / [GHz] Lower barycentric freq bound, signal side\n",
       "FRQSIGHI=     367.814047923905 / [GHz] Upper barycentric freq bound, signal side\n",
       "FRQIMGLO=                      / [GHz] Lower barycentric freq bound, image sideb\n",
       "FRQIMGHI=                      / [GHz] Upper barycentric freq bound, image sideb\n",
       "OBSRA   =     283.327491218101 / [deg] Reference ICRS RA coordinate             \n",
       "MJD-OBS =     56048.6984143518 / MJD of start of observation                    \n",
       "MJD-END =     56048.7020949074 / MJD of end of observation                      \n",
       "ASN_TYPE= 'night   '           / Time-based selection criterion                 \n",
       "FCF     =               537000 / [mJy/beam/pW] Flux conversion factor           \n",
       "ASN_ID  = '07065cfd200a6a892db557cb5779f110' / Association Identifier           \n",
       "ELAPTIME=     318.241433652546 / [s] Total duration of all observations in map  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from starlink.utilities import get_ndf_fitshdr\n",
    "fitsheader = get_ndf_fitshdr(file)\n",
    "fitsheader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
